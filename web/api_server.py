"""
ğŸš€ FastAPI REST API Server
AutoTicket Classifier iÃ§in RESTful API
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Optional
import joblib
import json
import os
import sys
import time
from datetime import datetime

# Kendi modÃ¼llerimizi import et
sys.path.append('..')
from utils.text_preprocessing import TurkishTextPreprocessor
from utils.feature_extraction import FeatureExtractor
from models.naive_bayes import NaiveBayesClassifier
from models.logistic_regression import LogisticRegressionClassifier

# FastAPI uygulamasÄ±
app = FastAPI(
    title="ğŸ« AutoTicket Classifier API",
    description="MÃ¼ÅŸteri destek taleplerini otomatik etiketleyen AI API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic modelleri
class TicketText(BaseModel):
    text: str
    model_name: Optional[str] = "logistic_regression"

class BatchTickets(BaseModel):
    texts: List[str]
    model_name: Optional[str] = "logistic_regression"

class PredictionResponse(BaseModel):
    category: str
    category_tr: str
    confidence: float
    probabilities: Dict[str, float]
    processing_time: float
    model_used: str

class BatchPredictionResponse(BaseModel):
    predictions: List[PredictionResponse]
    total_processing_time: float
    model_used: str

class ModelInfo(BaseModel):
    available_models: List[str]
    default_model: str
    categories: Dict[str, str]

# Global deÄŸiÅŸkenler
models = {}
preprocessor = None
feature_extractor = None
tfidf_vectorizer = None
label_encoder = None
category_translations = {
    "payment_issue": "ğŸ’³ Ã–deme Sorunu",
    "reservation_problem": "ğŸ“… Rezervasyon Problemi",
    "user_error": "ğŸ‘¤ KullanÄ±cÄ± HatasÄ±",
    "complaint": "ğŸ˜ Åikayet",
    "general_info": "â“ Genel Bilgi",
    "technical_issue": "ğŸ”§ Teknik Sorun"
}

def load_models():
    """EÄŸitilmiÅŸ modelleri ve araÃ§larÄ± yÃ¼kle"""
    global models, preprocessor, feature_extractor, tfidf_vectorizer, label_encoder
    
    models = {}
    preprocessor = TurkishTextPreprocessor()
    feature_extractor = FeatureExtractor()
    tfidf_vectorizer = None
    label_encoder = None
    
    model_dir = "../models/trained"
    
    # TF-IDF vectorizer'Ä± yÃ¼kle
    tfidf_path = os.path.join(model_dir, "tfidf_vectorizer.joblib")
    if os.path.exists(tfidf_path):
        tfidf_vectorizer = joblib.load(tfidf_path)
        print("âœ… TF-IDF vectorizer yÃ¼klendi")
    
    # Label encoder'Ä± yÃ¼kle
    encoder_path = os.path.join(model_dir, "label_encoder.joblib")
    if os.path.exists(encoder_path):
        label_encoder = joblib.load(encoder_path)
        print("âœ… Label encoder yÃ¼klendi")
    
    if os.path.exists(model_dir):
        # Naive Bayes
        nb_path = os.path.join(model_dir, "naive_bayes_model.joblib")
        if os.path.exists(nb_path):
            try:
                models['naive_bayes'] = joblib.load(nb_path)
                print("âœ… Naive Bayes modeli yÃ¼klendi")
            except Exception as e:
                print(f"âŒ Naive Bayes yÃ¼klenemedi: {e}")
        
        # Logistic Regression
        lr_path = os.path.join(model_dir, "logistic_regression_model.joblib")
        if os.path.exists(lr_path):
            try:
                models['logistic_regression'] = joblib.load(lr_path)
                print("âœ… Logistic Regression modeli yÃ¼klendi")
            except Exception as e:
                print(f"âŒ Logistic Regression yÃ¼klenemedi: {e}")
    
    if not models:
        print("âš ï¸ HiÃ§ model yÃ¼klenemedi! Demo modu aktif.")

def predict_with_model(text: str, model_name: str):
    """Belirtilen modelle tahmin yap"""
    if model_name not in models:
        raise HTTPException(
            status_code=404, 
            detail=f"Model '{model_name}' bulunamadÄ±. Mevcut modeller: {list(models.keys())}"
        )
    
    start_time = time.time()
    
    try:
        # Metin Ã¶n iÅŸleme
        processed_text = preprocessor.preprocess_text(
            text, 
            remove_stopwords=True, 
            apply_stemming=False
        )
        
        if not processed_text.strip():
            raise HTTPException(
                status_code=400,
                detail="Metin Ã¶n iÅŸlemeden sonra boÅŸ kaldÄ±"
            )
        
        # GerÃ§ek model varsa kullan
        if tfidf_vectorizer and label_encoder and model_name in models:
            model = models[model_name]
            
            # TF-IDF dÃ¶nÃ¼ÅŸÃ¼mÃ¼
            text_features = tfidf_vectorizer.transform([processed_text])
            
            # Tahmin yap
            prediction = model.predict(text_features)[0]
            probabilities = model.predict_proba(text_features)[0]
            
            # Label encoder ile kategori ismine Ã§evir
            predicted_category = label_encoder.inverse_transform([prediction])[0]
            confidence = float(max(probabilities))
            
            # TÃ¼m kategoriler iÃ§in olasÄ±lÄ±klar
            all_categories = label_encoder.classes_
            prob_dict = {cat: float(prob) for cat, prob in zip(all_categories, probabilities)}
            
        else:
            # Fallback: SimÃ¼le edilmiÅŸ tahmin
            import numpy as np
            
            # Basit kural tabanlÄ± tahmin
            text_lower = text.lower()
            
            if any(word in text_lower for word in ['Ã¶deme', 'para', 'fatura', 'kredi', 'kart']):
                predicted_category = "Ã–deme Sorunu"
                confidence = 0.85
            elif any(word in text_lower for word in ['rezervasyon', 'iptal', 'deÄŸiÅŸtir', 'tarih']):
                predicted_category = "Rezervasyon Problemi" 
                confidence = 0.82
            elif any(word in text_lower for word in ['ÅŸifre', 'giriÅŸ', 'hesap', 'kullanÄ±cÄ±']):
                predicted_category = "KullanÄ±cÄ± HatasÄ±"
                confidence = 0.78
            elif any(word in text_lower for word in ['ÅŸikayet', 'kÃ¶tÃ¼', 'memnun', 'problem']):
                predicted_category = "Åikayet"
                confidence = 0.88
            elif any(word in text_lower for word in ['nedir', 'nasÄ±l', 'ne zaman', 'bilgi']):
                predicted_category = "Genel Bilgi"
                confidence = 0.75
            elif any(word in text_lower for word in ['Ã§alÄ±ÅŸmÄ±yor', 'hata', 'aÃ§Ä±lmÄ±yor', 'yavaÅŸ']):
                predicted_category = "Teknik Sorun"
                confidence = 0.90
            else:
                predicted_category = "Genel Bilgi"
                confidence = 0.65
            
            # DiÄŸer kategoriler iÃ§in dÃ¼ÅŸÃ¼k olasÄ±lÄ±klar
            categories = ["Ã–deme Sorunu", "Rezervasyon Problemi", "KullanÄ±cÄ± HatasÄ±", 
                         "Åikayet", "Genel Bilgi", "Teknik Sorun"]
            prob_dict = {cat: 0.1 if cat != predicted_category else confidence for cat in categories}
        
        processing_time = time.time() - start_time
        
        # Kategori Ã§evirisi iÃ§in mapping
        tr_mapping = {
            "Ã–deme Sorunu": "ğŸ’³ Ã–deme Sorunu",
            "Rezervasyon Problemi": "ğŸ“… Rezervasyon Problemi", 
            "KullanÄ±cÄ± HatasÄ±": "ğŸ‘¤ KullanÄ±cÄ± HatasÄ±",
            "Åikayet": "ğŸ˜ Åikayet",
            "Genel Bilgi": "â“ Genel Bilgi",
            "Teknik Sorun": "ğŸ”§ Teknik Sorun"
        }
        
        return PredictionResponse(
            category=predicted_category,
            category_tr=tr_mapping.get(predicted_category, predicted_category),
            confidence=float(confidence),
            probabilities=prob_dict,
            processing_time=processing_time,
            model_used=model_name
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Tahmin hatasÄ±: {str(e)}")

# API Endpoints

@app.on_event("startup")
async def startup_event():
    """Uygulama baÅŸlangÄ±cÄ±nda modelleri yÃ¼kle"""
    print("ğŸš€ AutoTicket Classifier API baÅŸlatÄ±lÄ±yor...")
    load_models()
    print(f"âœ… {len(models)} model yÃ¼klendi")

@app.get("/")
async def root():
    """Ana endpoint"""
    return {
        "message": "ğŸ« AutoTicket Classifier API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health")
async def health_check():
    """SaÄŸlÄ±k kontrolÃ¼"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "models_loaded": len(models),
        "available_models": list(models.keys())
    }

@app.get("/models", response_model=ModelInfo)
async def get_model_info():
    """Model bilgilerini getir"""
    return ModelInfo(
        available_models=list(models.keys()),
        default_model="logistic_regression" if "logistic_regression" in models else list(models.keys())[0] if models else "",
        categories=category_translations
    )

@app.post("/predict", response_model=PredictionResponse)
async def predict_ticket(ticket: TicketText):
    """Tek ticket tahminÄ±"""
    if not models:
        raise HTTPException(
            status_code=503,
            detail="HiÃ§ model yÃ¼klenmemiÅŸ. Ã–nce modelleri eÄŸitin."
        )
    
    if not ticket.text.strip():
        raise HTTPException(
            status_code=400,
            detail="BoÅŸ metin gÃ¶nderilemez"
        )
    
    return predict_with_model(ticket.text, ticket.model_name)

@app.post("/batch_predict", response_model=BatchPredictionResponse)
async def batch_predict_tickets(batch: BatchTickets):
    """Toplu ticket tahminÄ±"""
    if not models:
        raise HTTPException(
            status_code=503,
            detail="HiÃ§ model yÃ¼klenmemiÅŸ"
        )
    
    if not batch.texts:
        raise HTTPException(
            status_code=400,
            detail="En az bir metin gÃ¶nderilmelidir"
        )
    
    start_time = time.time()
    predictions = []
    
    for text in batch.texts:
        if text.strip():  # BoÅŸ metinleri atla
            try:
                prediction = predict_with_model(text, batch.model_name)
                predictions.append(prediction)
            except Exception as e:
                # HatalÄ± tahminleri atla veya hata bilgisi ekle
                predictions.append(PredictionResponse(
                    category="error",
                    category_tr="âŒ Hata",
                    confidence=0.0,
                    probabilities={},
                    processing_time=0.0,
                    model_used=batch.model_name
                ))
    
    total_time = time.time() - start_time
    
    return BatchPredictionResponse(
        predictions=predictions,
        total_processing_time=total_time,
        model_used=batch.model_name
    )

@app.get("/categories")
async def get_categories():
    """Mevcut kategorileri getir"""
    return {
        "categories": category_translations,
        "count": len(category_translations)
    }

@app.get("/stats")
async def get_stats():
    """API istatistikleri"""
    # GerÃ§ek uygulamada database'den gelecek
    import numpy as np
    
    return {
        "total_predictions": np.random.randint(1000, 5000),
        "daily_predictions": np.random.randint(100, 500),
        "average_accuracy": round(np.random.uniform(0.85, 0.95), 3),
        "average_response_time": round(np.random.uniform(0.1, 0.5), 3),
        "most_used_model": "logistic_regression",
        "most_common_category": "payment_issue"
    }

# Hata yakalayÄ±cÄ±lar
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return {
        "error": "Endpoint bulunamadÄ±",
        "available_endpoints": [
            "/docs", "/health", "/models", "/predict", 
            "/batch_predict", "/categories", "/stats"
        ]
    }

@app.exception_handler(500)
async def internal_error_handler(request, exc):
    return {
        "error": "Sunucu hatasÄ±",
        "message": "LÃ¼tfen daha sonra tekrar deneyin"
    }

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ AutoTicket Classifier API Server")
    print("="*50)
    print("ğŸ“š DokÃ¼mantasyon: http://localhost:8000/docs")
    print("ğŸ”— API: http://localhost:8000")
    print("â¤ï¸  SaÄŸlÄ±k: http://localhost:8000/health")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
