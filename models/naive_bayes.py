"""
ğŸ¯ Naive Bayes Classifier
Baseline model olarak Multinomial Naive Bayes implementasyonu
"""

import numpy as np
import pandas as pd
from sklearn.naive_bayes import MultinomialNB, GaussianNB
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report
import joblib
import time

class NaiveBayesClassifier:
    def __init__(self, model_type='multinomial'):
        """
        Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±
        
        Args:
            model_type: 'multinomial' veya 'gaussian'
        """
        self.model_type = model_type
        self.model = None
        self.pipeline = None
        self.is_trained = False
        self.feature_names = None
        self.classes = None
        
        # Model seÃ§imi
        if model_type == 'multinomial':
            self.model = MultinomialNB()
        elif model_type == 'gaussian':
            self.model = GaussianNB()
        else:
            raise ValueError("model_type 'multinomial' veya 'gaussian' olmalÄ±")
    
    def train(self, X_train, y_train, feature_names=None):
        """Modeli eÄŸit"""
        print(f"ğŸ¯ Naive Bayes ({self.model_type}) eÄŸitimi baÅŸlÄ±yor...")
        
        start_time = time.time()
        
        # Veri tipini kontrol et
        if hasattr(X_train, 'toarray'):  # Sparse matrix ise
            if self.model_type == 'gaussian':
                X_train = X_train.toarray()
        
        # Modeli eÄŸit
        self.model.fit(X_train, y_train)
        
        training_time = time.time() - start_time
        
        # Model bilgilerini kaydet
        self.is_trained = True
        self.feature_names = feature_names
        self.classes = self.model.classes_
        
        print(f"âœ… EÄŸitim tamamlandÄ±! SÃ¼re: {training_time:.2f}s")
        print(f"   SÄ±nÄ±f sayÄ±sÄ±: {len(self.classes)}")
        print(f"   Ã–zellik sayÄ±sÄ±: {X_train.shape[1]}")
        
        return training_time
    
    def fit(self, X, y):
        """Sklearn uyumluluÄŸu iÃ§in fit metodu"""
        return self.train(X, y)
    
    def predict(self, X_test):
        """Tahmin yap"""
        if not self.is_trained:
            raise ValueError("Model henÃ¼z eÄŸitilmemiÅŸ!")
        
        # Veri tipini kontrol et
        if hasattr(X_test, 'toarray') and self.model_type == 'gaussian':
            X_test = X_test.toarray()
        
        return self.model.predict(X_test)
    
    def predict_proba(self, X_test):
        """OlasÄ±lÄ±k tahminleri"""
        if not self.is_trained:
            raise ValueError("Model henÃ¼z eÄŸitilmemiÅŸ!")
        
        # Veri tipini kontrol et
        if hasattr(X_test, 'toarray') and self.model_type == 'gaussian':
            X_test = X_test.toarray()
        
        return self.model.predict_proba(X_test)
    
    def get_feature_importance(self, top_n=10):
        """
        Ã–zellik Ã¶nemini hesapla (sadece MultinomialNB iÃ§in)
        Log-probability deÄŸerlerini kullanÄ±r
        """
        if not self.is_trained:
            raise ValueError("Model henÃ¼z eÄŸitilmemiÅŸ!")
        
        if self.model_type != 'multinomial':
            print("âš ï¸ Ã–zellik Ã¶nemi sadece MultinomialNB iÃ§in hesaplanabilir")
            return None
        
        # Feature log-probabilities
        feature_log_prob = self.model.feature_log_prob_
        
        importance_data = []
        
        for i, class_name in enumerate(self.classes):
            # Bu sÄ±nÄ±f iÃ§in en Ã¶nemli Ã¶zellikler
            class_importance = feature_log_prob[i]
            top_indices = np.argsort(class_importance)[::-1][:top_n]
            
            for rank, idx in enumerate(top_indices):
                importance_data.append({
                    'class': class_name,
                    'feature_index': idx,
                    'feature_name': self.feature_names[idx] if self.feature_names is not None else f"feature_{idx}",
                    'log_probability': class_importance[idx],
                    'rank': rank + 1
                })
        
        return pd.DataFrame(importance_data)
    
    def hyperparameter_tuning(self, X_train, y_train, cv=5):
        """Hiperparametre optimizasyonu"""
        print("ğŸ”§ Hiperparametre optimizasyonu baÅŸlÄ±yor...")
        
        if self.model_type == 'multinomial':
            param_grid = {
                'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],
                'fit_prior': [True, False]
            }
        else:  # gaussian
            param_grid = {
                'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]
            }
        
        # Grid search
        grid_search = GridSearchCV(
            self.model,
            param_grid,
            cv=cv,
            scoring='f1_weighted',
            n_jobs=-1,
            verbose=1
        )
        
        # Veri tipini kontrol et
        if hasattr(X_train, 'toarray') and self.model_type == 'gaussian':
            X_train = X_train.toarray()
        
        grid_search.fit(X_train, y_train)
        
        # En iyi modeli kullan
        self.model = grid_search.best_estimator_
        self.is_trained = True
        
        print(f"âœ… En iyi parametreler: {grid_search.best_params_}")
        print(f"âœ… En iyi CV skoru: {grid_search.best_score_:.4f}")
        
        return grid_search.best_params_, grid_search.best_score_
    
    def save_model(self, filepath):
        """Modeli kaydet"""
        try:
            if not self.is_trained:
                raise ValueError("Model henÃ¼z eÄŸitilmemiÅŸ!")
            
            model_data = {
                'model': self.model,
                'model_type': self.model_type,
                'feature_names': self.feature_names,
                'classes': self.classes,
                'is_trained': self.is_trained
            }
            
            joblib.dump(model_data, filepath)
            print(f"ğŸ’¾ Model kaydedildi: {filepath}")
        except Exception as e:
            print(f"âŒ Model kaydetme hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def load_model(self, filepath):
        """Modeli yÃ¼kle"""
        model_data = joblib.load(filepath)
        
        self.model = model_data['model']
        self.model_type = model_data['model_type']
        self.feature_names = model_data['feature_names']
        self.classes = model_data['classes']
        self.is_trained = model_data['is_trained']
        
        print(f"ğŸ“‚ Model yÃ¼klendi: {filepath}")
    
    def get_model_info(self):
        """Model bilgilerini getir"""
        if not self.is_trained:
            return "Model henÃ¼z eÄŸitilmemiÅŸ"
        
        info = {
            'model_type': self.model_type,
            'n_classes': len(self.classes),
            'classes': list(self.classes),
            'n_features': len(self.feature_names) if self.feature_names else "Bilinmiyor"
        }
        
        if self.model_type == 'multinomial':
            info['alpha'] = self.model.alpha
            info['fit_prior'] = self.model.fit_prior
        else:
            info['var_smoothing'] = self.model.var_smoothing
        
        return info

def train_naive_bayes_pipeline(X_train, y_train, X_test, y_test, 
                              feature_names=None, model_type='multinomial'):
    """Naive Bayes eÄŸitim pipeline'Ä±"""
    print(f"ğŸš€ Naive Bayes Pipeline BaÅŸlÄ±yor ({model_type})")
    print("="*50)
    
    # Model oluÅŸtur
    nb_classifier = NaiveBayesClassifier(model_type=model_type)
    
    # EÄŸit
    training_time = nb_classifier.train(X_train, y_train, feature_names)
    
    # Test et
    print("\nğŸ§ª Test seti Ã¼zerinde deÄŸerlendirme...")
    start_time = time.time()
    y_pred = nb_classifier.predict(X_test)
    prediction_time = time.time() - start_time
    
    # Metrikleri hesapla
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"âœ… Test SonuÃ§larÄ±:")
    print(f"   Accuracy: {accuracy:.4f}")
    print(f"   Tahmin sÃ¼resi: {prediction_time:.4f}s")
    
    # DetaylÄ± rapor
    print(f"\nğŸ“‹ SÄ±nÄ±flandÄ±rma Raporu:")
    print(classification_report(y_test, y_pred, target_names=nb_classifier.classes))
    
    # Ã–zellik Ã¶nemi (sadece multinomial iÃ§in)
    if model_type == 'multinomial' and feature_names is not None:
        print(f"\nğŸ† En Ã–nemli Ã–zellikler:")
        importance_df = nb_classifier.get_feature_importance(top_n=5)
        if importance_df is not None:
            for class_name in nb_classifier.classes[:3]:  # Ä°lk 3 sÄ±nÄ±f
                class_features = importance_df[importance_df['class'] == class_name]
                print(f"\n   ğŸ“‚ {class_name}:")
                for _, row in class_features.head(3).iterrows():
                    print(f"      {row['rank']}. {row['feature_name']} ({row['log_probability']:.4f})")
    
    return nb_classifier, {
        'accuracy': accuracy,
        'training_time': training_time,
        'prediction_time': prediction_time,
        'y_pred': y_pred
    }

def demo_naive_bayes():
    """Naive Bayes demo'su"""
    print("ğŸ§ª Naive Bayes Demo")
    print("="*30)
    
    # Ã–rnek veri oluÅŸtur
    from sklearn.datasets import make_classification
    from sklearn.feature_extraction.text import TfidfVectorizer
    
    # Sentetik veri
    X, y = make_classification(
        n_samples=1000,
        n_features=100,
        n_classes=3,
        n_informative=50,
        random_state=42
    )
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Multinomial NB test (non-negative features gerekli)
    X_train_pos = np.abs(X_train)
    X_test_pos = np.abs(X_test)
    
    print("1. Multinomial Naive Bayes:")
    nb_multi, results_multi = train_naive_bayes_pipeline(
        X_train_pos, y_train, X_test_pos, y_test, 
        model_type='multinomial'
    )
    
    print("\n" + "="*50)
    print("2. Gaussian Naive Bayes:")
    nb_gauss, results_gauss = train_naive_bayes_pipeline(
        X_train, y_train, X_test, y_test,
        model_type='gaussian'
    )
    
    # KarÅŸÄ±laÅŸtÄ±rma
    print(f"\nğŸ“Š KarÅŸÄ±laÅŸtÄ±rma:")
    print(f"Multinomial NB - Accuracy: {results_multi['accuracy']:.4f}, SÃ¼re: {results_multi['training_time']:.3f}s")
    print(f"Gaussian NB   - Accuracy: {results_gauss['accuracy']:.4f}, SÃ¼re: {results_gauss['training_time']:.3f}s")

if __name__ == "__main__":
    demo_naive_bayes()
