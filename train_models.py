"""
ğŸ“ Ana Model EÄŸitim Scripti - Enhanced
TÃ¼m modelleri eÄŸitir, kapsamlÄ± deÄŸerlendirme ve monitoring ile
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import os
import json
import time
import matplotlib.pyplot as plt

# Kendi modÃ¼llerimizi import et
from utils.text_preprocessing import TurkishTextPreprocessor
from utils.feature_extraction import FeatureExtractor
from utils.evaluation import ModelEvaluator
from models.naive_bayes import NaiveBayesClassifier, train_naive_bayes_pipeline
from models.logistic_regression import LogisticRegressionClassifier, train_logistic_regression_pipeline
from models.bert_classifier import BERTTextClassifier, train_bert_pipeline

# Entegre edilmiÅŸ iyileÅŸtirmeleri import et
from utils.evaluation import ModelEvaluator as AdvancedEvaluator
from utils.monitoring import ProductionMonitor as PerformanceMonitor
from models.ensemble_system import EnsembleManager
# ABTestingFramework artÄ±k ayrÄ± bir utility olarak implement edilecek

class EnhancedModelTrainer:
    def __init__(self, data_path="data/processed_data.csv"):
        """
        GeliÅŸmiÅŸ Model eÄŸitim sÄ±nÄ±fÄ± - TÃ¼m iyileÅŸtirmelerle entegre
        
        Args:
            data_path: Ä°ÅŸlenmiÅŸ veri dosyasÄ±nÄ±n yolu
        """
        self.data_path = data_path
        self.df = None
        self.X_train = None
        self.X_test = None
        self.X_val = None
        self.y_train = None
        self.y_test = None
        self.y_val = None
        
        # Temel bileÅŸenler
        self.preprocessor = TurkishTextPreprocessor()
        self.feature_extractor = FeatureExtractor()
        self.evaluator = ModelEvaluator()
        
        # GeliÅŸmiÅŸ bileÅŸenler
        self.advanced_evaluator = AdvancedEvaluator()
        self.drift_detector = None  # EÄŸitim sonrasÄ± initialize edilecek
        self.performance_monitor = PerformanceMonitor()
        self.ab_tester = None  # ABTestingFramework ayrÄ± class olarak tanÄ±mlanacak
        self.ensemble_manager = EnsembleManager()
        
        self.results = {}
        self.models = {}
        self.comprehensive_results = {}
        
        # Model save dizini
        os.makedirs("models/trained", exist_ok=True)
        os.makedirs("evaluation_results", exist_ok=True)
        os.makedirs("monitoring", exist_ok=True)
    
    def load_data(self):
        """Veriyi yÃ¼kle"""
        print("ğŸ“‚ Veri yÃ¼kleniyor...")
        
        if not os.path.exists(self.data_path):
            raise FileNotFoundError(f"Veri dosyasÄ± bulunamadÄ±: {self.data_path}")
        
        self.df = pd.read_csv(self.data_path)
        
        print(f"âœ… {len(self.df)} adet ticket yÃ¼klendi")
        print(f"ğŸ“Š Kategori daÄŸÄ±lÄ±mÄ±:")
        print(self.df['category_tr'].value_counts())
        
        return self.df
    
    def preprocess_data(self, test_size=0.2, val_size=0.1, random_state=42):
        """Veriyi Ã¶n iÅŸle ve bÃ¶l"""
        print("\nğŸ”§ Veri Ã¶n iÅŸleme baÅŸlÄ±yor...")
        
        # Metin Ã¶n iÅŸleme
        self.df = self.preprocessor.preprocess_dataframe(
            self.df, 
            text_column='message',
            new_column='processed_text',
            remove_stopwords=True,
            apply_stemming=False,
            min_length=2
        )
        
        # BoÅŸ metinleri filtrele
        initial_count = len(self.df)
        self.df = self.df[self.df['processed_text'].str.len() > 0]
        filtered_count = len(self.df)
        
        if initial_count != filtered_count:
            print(f"âš ï¸  {initial_count - filtered_count} adet boÅŸ metin filtrelendi")
        
        # Features ve labels
        X = self.df['processed_text'].values
        y = self.df['category'].values
        
        # Train-test split
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        # Train-validation split
        if val_size > 0:
            val_size_adjusted = val_size / (1 - test_size)
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=val_size_adjusted, 
                random_state=random_state, stratify=y_temp
            )
            self.X_val = X_val
            self.y_val = y_val
        else:
            X_train, y_train = X_temp, y_temp
            self.X_val = None
            self.y_val = None
        
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test
        
        print(f"âœ… Veri bÃ¶lÃ¼nmesi tamamlandÄ±:")
        print(f"   Train: {len(X_train)} samples")
        print(f"   Validation: {len(X_val) if X_val is not None else 0} samples")
        print(f"   Test: {len(X_test)} samples")
        
        return True
    
    def extract_features_once(self):
        """TÃ¼m modeller iÃ§in ortak TF-IDF features oluÅŸtur"""
        print("\nğŸ”¤ Ortak TF-IDF features oluÅŸturuluyor...")
        
        # Tek bir TF-IDF vectorizer ile tÃ¼m features oluÅŸtur
        self.tfidf_matrix_train, self.feature_names = self.feature_extractor.extract_tfidf_features(
            self.X_train, max_features=2000  # Ortak feature sayÄ±sÄ±
        )
        self.tfidf_matrix_test = self.feature_extractor.transform_new_text(
            self.X_test, feature_type='tfidf'
        )
        
        if self.X_val is not None:
            self.tfidf_matrix_val = self.feature_extractor.transform_new_text(
                self.X_val, feature_type='tfidf'
            )
        else:
            self.tfidf_matrix_val = None
        
        print(f"âœ… TF-IDF features hazÄ±rlandÄ±: {self.tfidf_matrix_train.shape[1]} features")
        return True
    
    def train_naive_bayes(self, model_type='multinomial'):
        """Naive Bayes modelini eÄŸit - ortak TF-IDF kullanarak"""
        print(f"\nğŸ¯ Naive Bayes ({model_type}) EÄŸitimi")
        print("="*50)
        
        # Ortak TF-IDF features kullan
        if not hasattr(self, 'tfidf_matrix_train'):
            raise ValueError("Ã–nce extract_features_once() Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±!")
        
        # Model oluÅŸtur ve eÄŸit (pipeline yerine direkt eÄŸitim)
        from models.naive_bayes import NaiveBayesClassifier
        import time
        
        start_time = time.time()
        
        # Model oluÅŸtur
        nb_model = NaiveBayesClassifier(model_type=model_type)
        
        # EÄŸit
        nb_model.train(self.tfidf_matrix_train, self.y_train)
        
        # Test et
        predict_start = time.time()
        y_pred = nb_model.predict(self.tfidf_matrix_test)
        predict_time = time.time() - predict_start
        
        training_time = time.time() - start_time
        
        # Accuracy hesapla
        from sklearn.metrics import accuracy_score
        accuracy = accuracy_score(self.y_test, y_pred)
        
        # SonuÃ§larÄ± hazÄ±rla
        results = {
            'accuracy': accuracy,
            'training_time': training_time,
            'prediction_time': predict_time,
            'y_pred': y_pred,
            'y_true': self.y_test
        }
        
        # Kaydet
        model_name = f"naive_bayes_{model_type}"
        nb_model.save_model(f"models/trained/{model_name}.pkl")
        
        self.models[model_name] = nb_model
        self.results[model_name] = results
        
        print(f"âœ… Naive Bayes ({model_type}) eÄŸitimi tamamlandÄ±!")
        print(f"ğŸ“Š Accuracy: {accuracy:.4f}")
        print(f"â±ï¸  EÄŸitim sÃ¼resi: {training_time:.2f}s")
        print(f"âš¡ Tahmin sÃ¼resi: {predict_time:.4f}s")
        
        # Evaluator'a ekle - sadece sonuÃ§larla, model prediction yapmadan
        eval_results = self.evaluator.evaluate_model(
            nb_model, self.tfidf_matrix_test, self.y_test, 
            y_pred=results['y_pred'], model_name=f"Naive Bayes ({model_type})"
        )
        
        return nb_model, results
    
    def train_logistic_regression(self, tune_hyperparams=False):
        """Logistic Regression modelini eÄŸit - ortak TF-IDF kullanarak"""
        print(f"\nğŸ¯ Logistic Regression EÄŸitimi")
        print("="*50)
        
        # Ortak TF-IDF features kullan
        if not hasattr(self, 'tfidf_matrix_train'):
            raise ValueError("Ã–nce extract_features_once() Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±!")
        
        # Model oluÅŸtur ve eÄŸit (pipeline yerine direkt eÄŸitim)
        from models.logistic_regression import LogisticRegressionClassifier
        import time
        
        start_time = time.time()
        
        # Model oluÅŸtur
        lr_model = LogisticRegressionClassifier()
        
        # Hyperparameter tuning opsiyonel
        if tune_hyperparams:
            print("ğŸ”§ Hyperparameter tuning aktif...")
            # Basit grid search
            from sklearn.model_selection import GridSearchCV
            from sklearn.linear_model import LogisticRegression
            
            param_grid = {
                'C': [0.1, 1.0, 10.0],
                'max_iter': [1000, 2000]
            }
            
            base_model = LogisticRegression(random_state=42)
            grid_search = GridSearchCV(base_model, param_grid, cv=3, scoring='accuracy')
            grid_search.fit(self.tfidf_matrix_train, self.y_train)
            
            # En iyi parametreleri kullan
            lr_model.model = grid_search.best_estimator_
            print(f"ğŸ¯ En iyi parametreler: {grid_search.best_params_}")
        else:
            # VarsayÄ±lan parametrelerle eÄŸit
            lr_model.train(self.tfidf_matrix_train, self.y_train)
        
        # Test et
        predict_start = time.time()
        y_pred = lr_model.predict(self.tfidf_matrix_test)
        predict_time = time.time() - predict_start
        
        training_time = time.time() - start_time
        
        # Accuracy hesapla
        from sklearn.metrics import accuracy_score
        accuracy = accuracy_score(self.y_test, y_pred)
        
        # SonuÃ§larÄ± hazÄ±rla
        results = {
            'accuracy': accuracy,
            'training_time': training_time,
            'prediction_time': predict_time,
            'y_pred': y_pred,
            'y_true': self.y_test
        }
        
        # Kaydet
        model_name = "logistic_regression"
        lr_model.save_model(f"models/trained/{model_name}.pkl")
        
        self.models[model_name] = lr_model
        self.results[model_name] = results
        
        print(f"âœ… Logistic Regression eÄŸitimi tamamlandÄ±!")
        print(f"ğŸ“Š Accuracy: {accuracy:.4f}")
        print(f"â±ï¸  EÄŸitim sÃ¼resi: {training_time:.2f}s")
        print(f"âš¡ Tahmin sÃ¼resi: {predict_time:.4f}s")
        
        # Evaluator'a ekle - sadece sonuÃ§larla, model prediction yapmadan
        eval_results = self.evaluator.evaluate_model(
            lr_model, self.tfidf_matrix_test, self.y_test,
            y_pred=results['y_pred'], model_name="Logistic Regression"
        )
        
        return lr_model, results
    
    def train_bert(self, model_name='dbmdz/bert-base-turkish-cased', epochs=3):
        """BERT modelini eÄŸit"""
        print(f"\nğŸ¤– BERT EÄŸitimi")
        print("="*50)
        
        # BERT raw text kullanÄ±r, sadece basit temizlik
        X_train_clean = [self.preprocessor.clean_text(text) for text in self.X_train]
        X_test_clean = [self.preprocessor.clean_text(text) for text in self.X_test]
        X_val_clean = None
        if self.X_val is not None:
            X_val_clean = [self.preprocessor.clean_text(text) for text in self.X_val]
        
        # Model eÄŸit
        bert_model, results = train_bert_pipeline(
            X_train_clean, self.y_train,
            X_test_clean, self.y_test,
            X_val_clean, self.y_val,
            model_name=model_name,
            epochs=epochs
        )
        
        # Kaydet
        model_save_name = "bert_classifier"
        bert_model.save_model(f"models/trained/{model_save_name}.pth")
        
        self.models[model_save_name] = bert_model
        self.results[model_save_name] = results
        
        # Evaluator'a ekle
        self.evaluator.evaluate_model(
            bert_model, X_test_clean, self.y_test,
            y_pred=results['y_pred'], model_name="BERT"
        )
        
        return bert_model, results
    
    def train_all_models(self, include_bert=True, bert_epochs=3):
        """TÃ¼m modelleri eÄŸit"""
        print("ğŸš€ TÃœM MODELLERÄ°N EÄÄ°TÄ°MÄ° BAÅLIYOR")
        print("="*60)
        
        start_time = time.time()
        
        # 0. Ortak TF-IDF features oluÅŸtur (TF-IDF kullanan modeller iÃ§in)
        print("\nğŸ”¤ Ortak TF-IDF features oluÅŸturuluyor...")
        self.extract_features_once()
        
        # 1. Naive Bayes (Multinomial)
        try:
            self.train_naive_bayes(model_type='multinomial')
        except Exception as e:
            print(f"âŒ Naive Bayes (Multinomial) hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
        
        # 2. Logistic Regression
        try:
            self.train_logistic_regression(tune_hyperparams=False)
        except Exception as e:
            print(f"âŒ Logistic Regression hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
        
        # 3. BERT (opsiyonel - uzun sÃ¼rÃ¼yor)
        if include_bert:
            try:
                self.train_bert(epochs=bert_epochs)
            except Exception as e:
                print(f"âŒ BERT hatasÄ±: {e}")
        else:
            print("â­ï¸  BERT eÄŸitimi atlandÄ± (include_bert=False)")
        
        total_time = time.time() - start_time
        
        print(f"\nâœ… TÃ¼m modellerin eÄŸitimi tamamlandÄ±!")
        print(f"â±ï¸  Toplam sÃ¼re: {total_time/60:.1f} dakika")
        
        return True
    
    def compare_models(self):
        """Modelleri karÅŸÄ±laÅŸtÄ±r"""
        print(f"\nğŸ“Š MODEL KARÅILAÅTIRMASI")
        print("="*60)
        
        if len(self.results) == 0:
            print("âŒ KarÅŸÄ±laÅŸtÄ±rÄ±lacak model bulunamadÄ±")
            return
        
        # Ã–zet tablo
        comparison_data = []
        for model_name, result in self.results.items():
            comparison_data.append({
                'Model': model_name,
                'Accuracy': result['accuracy'],
                'Training Time (s)': result.get('training_time', 'N/A'),
                'Prediction Time (s)': result['prediction_time']
            })
        
        df_comparison = pd.DataFrame(comparison_data)
        print(df_comparison.to_string(index=False))
        
        # GÃ¶rselleÅŸtirme
        if len(self.evaluator.results) > 0:
            try:
                # ModelEvaluator.compare_models sadece results parametresi alÄ±r
                self.evaluator.compare_models(self.evaluator.results)
                self.evaluator.plot_performance_vs_time()
            except Exception as e:
                print(f"âš ï¸ GÃ¶rselleÅŸtirme hatasÄ±: {e}")
                print("ğŸ“Š GÃ¶rselleÅŸtirme atlandÄ±, diÄŸer sonuÃ§lar kullanÄ±labilir")
        
        # Ã–zet rapor
        try:
            self.evaluator.generate_summary_report()
        except Exception as e:
            print(f"âš ï¸ Ã–zet rapor hatasÄ±: {e}")
            print("ğŸ“Š Rapor oluÅŸturma atlandÄ±")
        
        return df_comparison
    
    def save_results(self, filepath="models/training_results.json"):
        """SonuÃ§larÄ± JSON olarak kaydet"""
        results_to_save = {}
        
        for model_name, result in self.results.items():
            # Numpy arrays'i list'e Ã§evir
            result_copy = result.copy()
            if 'y_pred' in result_copy:
                y_pred = result_copy['y_pred']
                if hasattr(y_pred, 'tolist'):
                    result_copy['y_pred'] = y_pred.tolist()
                elif isinstance(y_pred, list):
                    result_copy['y_pred'] = y_pred
            
            results_to_save[model_name] = result_copy
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results_to_save, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ SonuÃ§lar kaydedildi: {filepath}")
        
        # TF-IDF vectorizer ve label encoder'Ä± da kaydet
        self.save_preprocessing_components()
    
    def save_preprocessing_components(self):
        """TF-IDF vectorizer ve label encoder'Ä± kaydet"""
        import joblib
        
        # TF-IDF vectorizer kaydet
        if hasattr(self.feature_extractor, 'tfidf_vectorizer') and self.feature_extractor.tfidf_vectorizer:
            joblib.dump(self.feature_extractor.tfidf_vectorizer, "models/trained/tfidf_vectorizer.joblib")
            print("ğŸ’¾ TF-IDF vectorizer kaydedildi")
        
        # Label encoder kaydet - Ã¶nce y_train'den oluÅŸtur
        if hasattr(self, 'y_train') and self.y_train is not None:
            from sklearn.preprocessing import LabelEncoder
            label_encoder = LabelEncoder()
            label_encoder.fit(self.y_train)
            joblib.dump(label_encoder, "models/trained/label_encoder.joblib")
            print("ğŸ’¾ Label encoder kaydedildi")
    
    def generate_report(self, save_path="models/model_training_report.md"):
        """Markdown formatÄ±nda rapor oluÅŸtur"""
        report = []
        report.append("# ğŸ« AutoTicket Classifier - Model EÄŸitim Raporu\n")
        report.append(f"ğŸ“… Tarih: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # Veri Ã¶zeti
        report.append("## ğŸ“Š Veri Ã–zeti\n")
        report.append(f"- Toplam ticket sayÄ±sÄ±: {len(self.df)}")
        report.append(f"- Train set: {len(self.X_train)} samples")
        report.append(f"- Test set: {len(self.X_test)} samples")
        if self.X_val is not None:
            report.append(f"- Validation set: {len(self.X_val)} samples")
        
        # Kategori daÄŸÄ±lÄ±mÄ±
        report.append("\n### Kategori DaÄŸÄ±lÄ±mÄ±")
        category_counts = pd.Series(self.y_train).value_counts()
        for category, count in category_counts.items():
            report.append(f"- {category}: {count}")
        
        # Model sonuÃ§larÄ±
        report.append("\n## ğŸ¤– Model SonuÃ§larÄ±\n")
        
        for model_name, result in self.results.items():
            report.append(f"### {model_name.replace('_', ' ').title()}")
            report.append(f"- **Accuracy**: {result['accuracy']:.4f}")
            if 'training_time' in result and result['training_time']:
                report.append(f"- **Training Time**: {result['training_time']:.2f}s")
            report.append(f"- **Prediction Time**: {result['prediction_time']:.4f}s")
            report.append("")
        
        # En iyi model
        if self.results:
            best_model = max(self.results.keys(), key=lambda x: self.results[x]['accuracy'])
            report.append(f"## ğŸ† En Ä°yi Model: {best_model.replace('_', ' ').title()}")
            report.append(f"- Accuracy: {self.results[best_model]['accuracy']:.4f}")
            report.append("")
        
        # Ã–neriler
        report.append("## ğŸ’¡ Ã–neriler\n")
        if self.results:
            best_accuracy = max(result['accuracy'] for result in self.results.values())
            if best_accuracy > 0.9:
                report.append("âœ… MÃ¼kemmel performans! Production'a hazÄ±r.")
            elif best_accuracy > 0.8:
                report.append("âœ… Ä°yi performans! KÃ¼Ã§Ã¼k iyileÅŸtirmeler yapÄ±labilir.")
            else:
                report.append("âš ï¸ Performans artÄ±rÄ±mÄ± gerekli.")
        
        # Dosyaya yaz
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        print(f"ğŸ“„ Rapor kaydedildi: {save_path}")
    
    def comprehensive_model_training_pipeline(self, enable_monitoring=True, enable_ab_testing=True):
        """
        KapsamlÄ± model eÄŸitim pipeline'Ä± - TÃ¼m iyileÅŸtirmelerle
        """
        print("ğŸš€ KAPSAMLI MODEL EÄÄ°TÄ°M PÄ°PELÄ°NE BAÅLATIYOR")
        print("=" * 70)
        
        # 1. Veri hazÄ±rlama
        print("\n1ï¸âƒ£ VERÄ° HAZIRLIÄI")
        self.load_data()
        self.preprocess_data()
        
        # 1.5. Ortak TF-IDF features oluÅŸtur
        print("\nğŸ”¤ Ortak TF-IDF features oluÅŸturuluyor...")
        self.extract_features_once()
        
        # 2. Temel modelleri eÄŸit
        print("\n2ï¸âƒ£ TEMEL MODEL EÄÄ°TÄ°MLERÄ°")
        models_to_train = ['naive_bayes', 'logistic_regression']
        
        # Her model iÃ§in comprehensive evaluation
        for model_name in models_to_train:
            print(f"\nğŸ¯ {model_name.upper()} - KapsamlÄ± EÄŸitim ve DeÄŸerlendirme")
            print("-" * 60)
            
            # Model eÄŸit
            if model_name == 'naive_bayes':
                model, results = self.train_naive_bayes()  # Tuple unpacking
                
            elif model_name == 'logistic_regression':
                model, results = self.train_logistic_regression()  # Tuple unpacking
            
            # Ortak TF-IDF matrix'leri kullan
            X_train_features = self.tfidf_matrix_train
            X_test_features = self.tfidf_matrix_test
            
            # Comprehensive evaluation - ÅŸimdi doÄŸru feature boyutlarÄ±yla
            evaluation_results = self.advanced_evaluator.comprehensive_model_evaluation(
                model.model if hasattr(model, 'model') else model,
                X_train_features, X_test_features, 
                self.y_train, self.y_test, 
                labels=np.unique(self.y_train),
                model_name=model_name
            )
            
            self.comprehensive_results[model_name] = evaluation_results
            self.models[model_name] = model
        
        # 3. Ensemble methods
        print("\n3ï¸âƒ£ ENSEMBLE METHODS")
        
        # Ortak TF-IDF matrix'lerini kullan
        ensemble_results = self._train_ensemble_models(self.tfidf_matrix_train, self.tfidf_matrix_test)
        
        # 4. A/B Testing setup
        if enable_ab_testing:
            print("\n4ï¸âƒ£ A/B TESTING KURULUMU")
            self._setup_ab_testing()
        
        # 5. Monitoring setup
        if enable_monitoring:
            print("\n5ï¸âƒ£ MONÄ°TORÄ°NG SÄ°STEMÄ° KURULUMU")
            self._setup_monitoring_system(X_train_features)
        
        # 6. Final reporting
        print("\n6ï¸âƒ£ KAPSAMLI RAPOR OLUÅTURMA")
        self._generate_comprehensive_report()
        
        print("\nğŸ‰ KAPSAMLI EÄÄ°TÄ°M PÄ°PELÄ°NE TAMAMLANDI!")
        
        return {
            'models': self.models,
            'comprehensive_results': self.comprehensive_results,
            'ensemble_results': ensemble_results
        }
    
    def _train_ensemble_models(self, X_train_features, X_test_features):
        """Ensemble modellerini eÄŸit"""
        print("ğŸ¤– Ensemble modelller eÄŸitiliyor...")
        
        # Ensemble manager kullanarak basit ensemble oluÅŸtur
        try:
            # Mevcut modelleri ensemble'a ekle
            ensemble_models = {}
            for name, model in self.models.items():
                if hasattr(model, 'model'):
                    ensemble_models[name] = model.model
                else:
                    ensemble_models[name] = model
            
            # Weighted ensemble oluÅŸtur
            from models.ensemble_system import WeightedEnsemble
            weighted_ensemble = WeightedEnsemble(models=ensemble_models, voting='soft')
            
            # EÄŸit
            weighted_ensemble.fit(X_train_features, self.y_train)
            
            # Test et
            ensemble_pred = weighted_ensemble.predict(X_test_features)
            ensemble_accuracy = (ensemble_pred == self.y_test).mean()
            
            print(f"âœ… Weighted Ensemble Accuracy: {ensemble_accuracy:.4f}")
            
            # Ensemble'Ä± kaydet
            self.models['weighted_ensemble'] = weighted_ensemble
            
            ensemble_results = {
                'weighted_ensemble': {
                    'accuracy': ensemble_accuracy,
                    'predictions': ensemble_pred
                }
            }
            
        except Exception as e:
            print(f"âš ï¸ Ensemble eÄŸitim hatasÄ±: {e}")
            ensemble_results = {}
        
        return ensemble_results
    
    def _setup_ab_testing(self):
        """A/B testing framework'Ã¼nÃ¼ kur"""
        print("ğŸ§ª A/B Testing framework kuruluyor...")
        
        # Model karÅŸÄ±laÅŸtÄ±rmalarÄ± iÃ§in testler kur
        model_names = list(self.models.keys())
        
        print("ğŸ“Š A/B Testing iÃ§in model karÅŸÄ±laÅŸtÄ±rmalarÄ±:")
        for i in range(len(model_names)):
            for j in range(i + 1, len(model_names)):
                model_a = model_names[i]
                model_b = model_names[j]
                
                test_name = f"{model_a}_vs_{model_b}"
                print(f"âœ… A/B Test tanÄ±mlandÄ±: {test_name}")
        
        print("âœ… A/B Testing framework kuruldu (placeholder - web app entegrasyonu gerekli)")
    
    def _setup_monitoring_system(self, reference_data):
        """Monitoring sistemini kur"""
        print("ğŸ“Š Monitoring sistemi kuruluyor...")
        
        # Performance monitor baseline data'yÄ± set et
        self.performance_monitor.set_baseline_data(
            reference_data.toarray() if hasattr(reference_data, 'toarray') else reference_data
        )
        
        # Initial performance metrics log
        for model_name, model in self.models.items():
            # Test accuracy
            if hasattr(model, 'model'):
                test_features = self.feature_extractor.transform_new_text(
                    self.X_test, feature_type='tfidf'
                )
                predictions = model.model.predict(test_features)
                accuracy = (predictions == self.y_test).mean()
                
                self.performance_monitor.log_performance_metric(
                    model_name, "accuracy", accuracy, len(self.y_test)
                )
        
        print("âœ… Monitoring sistemi kuruldu")
    
    def _generate_comprehensive_report(self):
        """KapsamlÄ± final raporu oluÅŸtur"""
        print("ğŸ“‹ KapsamlÄ± rapor oluÅŸturuluyor...")
        
        report_lines = []
        report_lines.append("ğŸ¯ AUTOTICKET CLASSIFIER - KAPSAMLI EÄÄ°TÄ°M RAPORU")
        report_lines.append("=" * 70)
        report_lines.append(f"ğŸ“… Rapor Tarihi: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # Dataset bilgisi
        report_lines.append("ğŸ“Š DATASET BÄ°LGÄ°SÄ°")
        report_lines.append("-" * 25)
        report_lines.append(f"Train samples: {len(self.X_train)}")
        report_lines.append(f"Test samples: {len(self.X_test)}")
        if self.X_val is not None:
            report_lines.append(f"Validation samples: {len(self.X_val)}")
        
        categories = np.unique(self.y_train)
        report_lines.append(f"Kategoriler: {', '.join(categories)}")
        report_lines.append("")
        
        # Model performanslarÄ±
        report_lines.append("ğŸ“ˆ MODEL PERFORMANSLARI")
        report_lines.append("-" * 30)
        
        model_scores = []
        for model_name, results in self.comprehensive_results.items():
            if 'cross_validation' in results and 'accuracy' in results['cross_validation']:
                cv_mean = results['cross_validation']['accuracy']['test_mean']
                cv_std = results['cross_validation']['accuracy']['test_std']
                
                # Learning curve overfitting gap
                overfitting_gap = results.get('learning_curves', {}).get('overfitting_gap', 0)
                
                model_scores.append({
                    'model': model_name,
                    'cv_accuracy': cv_mean,
                    'cv_std': cv_std,
                    'overfitting_gap': overfitting_gap
                })
                
                report_lines.append(f"ğŸ¤– {model_name.upper()}:")
                report_lines.append(f"   CV Accuracy: {cv_mean:.4f} Â± {cv_std:.4f}")
                report_lines.append(f"   Overfitting Gap: {overfitting_gap:.4f}")
                
                if overfitting_gap > 0.15:
                    report_lines.append("   âš ï¸ YÃ¼ksek overfitting riski")
                elif overfitting_gap > 0.1:
                    report_lines.append("   ğŸ”„ Orta overfitting riski")
                else:
                    report_lines.append("   âœ… Ä°yi generalization")
                
                report_lines.append("")
        
        # En iyi model
        if model_scores:
            best_model = max(model_scores, key=lambda x: x['cv_accuracy'])
            report_lines.append("ğŸ† EN Ä°YÄ° MODEL")
            report_lines.append("-" * 20)
            report_lines.append(f"Model: {best_model['model'].upper()}")
            report_lines.append(f"CV Accuracy: {best_model['cv_accuracy']:.4f}")
            report_lines.append("")
        
        # Ã–neriler
        report_lines.append("ğŸ’¡ Ã–NERÄ°LER")
        report_lines.append("-" * 15)
        
        if any(score['overfitting_gap'] > 0.15 for score in model_scores):
            report_lines.append("ğŸš¨ Overfitting problemi tespit edildi:")
            report_lines.append("   - Regularization parametrelerini artÄ±rÄ±n")
            report_lines.append("   - Feature selection uygulayÄ±n")
            report_lines.append("   - Daha fazla training data toplayÄ±n")
        
        report_lines.append("ğŸ“Š Production iÃ§in Ã¶neriler:")
        report_lines.append("   - Real-time monitoring aktif edilsin")
        report_lines.append("   - A/B testing ile model karÅŸÄ±laÅŸtÄ±rmasÄ± yapÄ±lsÄ±n")
        report_lines.append("   - Ensemble methods production'a alÄ±nsÄ±n")
        report_lines.append("   - Drift detection ile veri kalitesi izlensin")
        
        # Raporu kaydet
        report_text = "\n".join(report_lines)
        report_path = f"evaluation_results/comprehensive_training_report_{time.strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(report_text)
        print(f"\nğŸ’¾ KapsamlÄ± rapor kaydedildi: {report_path}")
        
        return report_path

def main():
    """Ana eÄŸitim fonksiyonu - Enhanced"""
    print("ï¿½ AutoTicket Classifier - GeliÅŸmiÅŸ Model EÄŸitimi")
    print("="*60)
    
    try:
        # Enhanced model trainer oluÅŸtur
        trainer = EnhancedModelTrainer()
        
        print("\nğŸ¯ EÄŸitim modunu seÃ§in:")
        print("1. Temel eÄŸitim (eski method)")
        print("2. ğŸš€ KapsamlÄ± eÄŸitim (TÃ¼m iyileÅŸtirmelerle)")
        
        choice = input("SeÃ§iminiz (1/2): ").strip()
        
        if choice == "2":
            # KapsamlÄ± eÄŸitim pipeline
            print("\nğŸ”§ KapsamlÄ± eÄŸitim seÃ§enekleri:")
            print("1. Monitoring aktif")
            print("2. A/B Testing aktif") 
            print("3. Her ikisi de aktif (Ã–nerilen)")
            
            options = input("SeÃ§iminiz (1/2/3): ").strip()
            
            enable_monitoring = options in ['1', '3']
            enable_ab_testing = options in ['2', '3']
            
            # KapsamlÄ± pipeline Ã§alÄ±ÅŸtÄ±r
            results = trainer.comprehensive_model_training_pipeline(
                enable_monitoring=enable_monitoring,
                enable_ab_testing=enable_ab_testing
            )
            
            print("\nğŸŠ KAPSAMLI EÄÄ°TÄ°M TAMAMLANDI!")
            print("âœ… Confusion matrix analizi tamamlandÄ±")
            print("âœ… K-fold cross validation tamamlandÄ±") 
            print("âœ… Learning curves ve overfitting kontrolÃ¼ tamamlandÄ±")
            print("âœ… Precision/Recall detaylÄ± analizi tamamlandÄ±")
            print("âœ… Model drift detection sistemi kuruldu")
            print("âœ… Performance monitoring dashboard hazÄ±r")
            print("âœ… Ensemble methods eÄŸitildi")
            print("âœ… A/B testing framework kuruldu")
            
        else:
            # Temel eÄŸitim (eski method)
            print("\nğŸ“Š Temel eÄŸitim modu:")
            
            # 1. Veri yÃ¼kle
            trainer.load_data()
            
            # 2. Veri Ã¶n iÅŸle  
            trainer.preprocess_data(test_size=0.2, val_size=0.1)
            
            # 3. Modelleri eÄŸit
            print("\nğŸ¯ Hangi modelleri eÄŸitmek istiyorsunuz?")
            print("1. Sadece hÄ±zlÄ± modeller (Naive Bayes + Logistic Regression)")
            print("2. TÃ¼m modeller (BERT dahil)")
            
            model_choice = input("SeÃ§iminiz (1/2): ").strip()
            
            if model_choice == "1":
                trainer.train_all_models(include_bert=False)
            else:
                epochs = input("BERT iÃ§in epoch sayÄ±sÄ± (varsayÄ±lan: 3): ").strip()
                epochs = int(epochs) if epochs.isdigit() else 3
                trainer.train_all_models(include_bert=True, bert_epochs=epochs)
            
            # 4. Modelleri karÅŸÄ±laÅŸtÄ±r
            trainer.compare_models()
            
            # 5. SonuÃ§larÄ± kaydet
            trainer.save_results()
            trainer.generate_report()
        
        print(f"\nğŸ‰ Model eÄŸitimi baÅŸarÄ±yla tamamlandÄ±!")
        print(f"ğŸ“ EÄŸitilmiÅŸ modeller: models/trained/")
        print(f"ğŸ“Š DeÄŸerlendirme sonuÃ§larÄ±: evaluation_results/")
        print(f"ğŸ“ˆ Monitoring verileri: monitoring/")
        
        # Ek bilgiler
        if choice == "2":
            print(f"\nï¿½ EK Ã–ZELLÄ°KLER:")
            print(f"ğŸ“Š Monitoring dashboard: monitoring_dashboard.html")
            print(f"ğŸ“ˆ Drift detection dashboard: drift_dashboard.html") 
            print(f"ğŸ§ª A/B testing sonuÃ§larÄ±: improvements/ dizininde")
            print(f"ğŸ¤– Ensemble modeller: models/ensemble/ dizininde")
        
    except Exception as e:
        print(f"âŒ Hata oluÅŸtu: {e}")
        import traceback
        traceback.print_exc()

def demo_comprehensive_training():
    """Comprehensive training demo"""
    print("ğŸ§ª COMPREHENSIVE TRAINING DEMO")
    print("=" * 40)
    
    trainer = EnhancedModelTrainer()
    
    # Generate sample data if needed
    if not os.path.exists("data/processed_data.csv"):
        print("ğŸ“Š Demo veri oluÅŸturuluyor...")
        from data_generator import TicketDataGenerator
        
        generator = TicketDataGenerator()
        df = generator.generate_comprehensive_dataset(n_samples=500)
        df.to_csv("data/processed_data.csv", index=False)
        print("âœ… Demo veri oluÅŸturuldu")
    
    # Run comprehensive pipeline
    results = trainer.comprehensive_model_training_pipeline(
        enable_monitoring=True,
        enable_ab_testing=True
    )
    
    return results

if __name__ == "__main__":
    main()
